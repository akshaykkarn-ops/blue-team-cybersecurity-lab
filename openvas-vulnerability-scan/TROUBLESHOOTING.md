Overview

During the deployment of OpenVAS (Greenbone Vulnerability Manager) on Kali Linux, multiple operational failures were encountered that prevented vulnerability scanning. Instead of reinstalling the system, a structured troubleshooting approach was followed to identify root causes, restore service dependencies, and achieve a fully operational vulnerability management platform.

This document outlines the issues encountered, root cause analysis, and recovery steps.
Issues Observed

The following symptoms were observed during setup:

OpenVAS web interface inaccessible or partially functional

Scan Configuration dropdown greyed out

PostgreSQL database initialization failures

OpenVAS feed synchronization not completing

GVM services inactive or repeatedly failing

Scanner registered but unable to execute scans

These symptoms indicated a cascading failure across multiple system layers.
Root Cause Analysis
1. Disk Space Exhaustion (Primary Root Cause)

Inspection of the root filesystem revealed that the / partition was at 100% utilization.

Impact:

PostgreSQL could not create or extend the GVM database

OpenVAS feeds failed to synchronize fully

GVM cache and lock files became corrupted

Service startup failures occurred without clear UI errors
2. Database Layer Failure (PostgreSQL)

Due to insufficient disk space:

PostgreSQL clusters were present but non-functional

GVM database initialization failed

gvmd was unable to register scan configurations
3. Feed Synchronization & NVT Cache Corruption

Feed updates were interrupted mid-process, resulting in:

Incomplete NVT data

Locked feed update states

Missing scan configurations

For safety, OpenVAS disabled scan execution until feeds were fully restored.
4. Service Dependency Chain Breakdown

OpenVAS relies on strict service ordering:

Redis

ospd-openvas

gvmd

gsad

Failures in lower layers propagated upward, causing UI availability without backend functionality.
Recovery & Troubleshooting Steps
Step 1: Restore Disk Capacity

Booted into Kali Live environment

Resized root filesystem using GParted

Reallocated space from /home to /

Ensured sufficient free disk space for feeds and databases

Step 2: Database Recovery

Verified PostgreSQL service status

Initialized PostgreSQL cluster

Recreated GVM database

Confirmed database socket availability
Step 3: Feed Rehydration

Restarted OpenVAS feed synchronization

Allowed NVT updates to complete fully

Avoided forcing rebuilds during active sync

Monitored logs to confirm completion

Step 4: Service Re-orchestration

Enabled all required services

Restarted services in correct dependency order

Verified socket and port availability
Validation

Successful recovery was confirmed by:

All GVM services active and running

OpenVAS web UI accessible on port 9392

Scan Configuration dropdown enabled

Successful execution of a Full and Fast scan

Vulnerability results generated correctly

Key Learnings

Disk capacity planning is critical for vulnerability management platforms

Service “running” state does not always indicate functional readiness

Feed synchronization must complete fully before scanning

Structured troubleshooting prevents unnecessary reinstallation
